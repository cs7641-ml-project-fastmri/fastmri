{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmri_common.args import Args\n",
    "from fastmri_common.subsample import MaskFunc\n",
    "from fastmri_data import transforms\n",
    "from fastmri_data.mri_data import SliceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pix2pix_data import create_datset\n",
    "from pix2pix_models import create_model\n",
    "from pix2pix_util.visualizer import Visualizer\n",
    "from pix2pix_options.train_options import TrainOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training U-Net models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, resolution, which_challenge, use_seed=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask_func (common.subsample.MaskFunc): A function that can create a mask of\n",
    "                appropriate shape.\n",
    "            resolution (int): Resolution of the image.\n",
    "            which_challenge (str): Either \"singlecoil\" or \"multicoil\" denoting the dataset.\n",
    "            use_seed (bool): If true, this class computes a pseudo random number generator seed\n",
    "                from the filename. This ensures that the same mask is used for all the slices of\n",
    "                a given volume every time.\n",
    "        \"\"\"\n",
    "        if which_challenge not in ('singlecoil', 'multicoil'):\n",
    "            raise ValueError(f'Challenge should either be \"singlecoil\" or \"multicoil\"')\n",
    "        self.mask_func = mask_func\n",
    "        self.resolution = resolution\n",
    "        self.which_challenge = which_challenge\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __call__(self, kspace, target, attrs, fname, slice_):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kspace (numpy.array): Input k-space of shape (num_coils, rows, cols, 2) for multi-coil\n",
    "                data or (rows, cols, 2) for single coil data.\n",
    "            target (numpy.array): Target image\n",
    "            attrs (dict): Acquisition related information stored in the HDF5 object.\n",
    "            fname (str): File name\n",
    "            slice (int): Serial number of the slice.\n",
    "        Returns:\n",
    "            (tuple): tuple containing:\n",
    "                image (torch.Tensor): Zero-filled input image.\n",
    "                target (torch.Tensor): Target image converted to a torch Tensor.\n",
    "                mean (float): Mean value used for normalization.\n",
    "                std (float): Standard deviation value used for normalization.\n",
    "                norm (float): L2 norm of the entire volume.\n",
    "        \"\"\"\n",
    "        kspace = transforms.to_tensor(kspace)\n",
    "        # Apply mask\n",
    "        seed = None if not self.use_seed else tuple(map(ord, fname))\n",
    "        masked_kspace, mask = transforms.apply_mask(kspace, self.mask_func, seed)\n",
    "        # Inverse Fourier Transform to get zero filled solution\n",
    "        image = transforms.ifft2(masked_kspace)\n",
    "        # Crop input image\n",
    "        image = transforms.complex_center_crop(image, (self.resolution, self.resolution))\n",
    "        # Absolute value\n",
    "        image = transforms.complex_abs(image)\n",
    "        # Apply Root-Sum-of-Squares if multicoil data\n",
    "        if self.which_challenge == 'multicoil':\n",
    "            image = transforms.root_sum_of_squares(image)\n",
    "        # Normalize input\n",
    "        image, mean, std = transforms.normalize_instance(image, eps=1e-11)\n",
    "        image = image.clamp(-6, 6)\n",
    "\n",
    "        target = transforms.to_tensor(target)\n",
    "        # Normalize target\n",
    "        target = transforms.normalize(target, mean, std, eps=1e-11)\n",
    "        target = target.clamp(-6, 6)\n",
    "        return image, target, mean, std, attrs['norm'].astype(np.float32)\n",
    "\n",
    "\n",
    "def create_datasets(args):\n",
    "    train_mask = MaskFunc(args.center_fractions, args.accelerations)\n",
    "    dev_mask = MaskFunc(args.center_fractions, args.accelerations)\n",
    "\n",
    "    train_data = SliceData(\n",
    "        root=args.data_path / f'{args.challenge}_train',\n",
    "        transform=DataTransform(train_mask, args.resolution, args.challenge),\n",
    "        sample_rate=args.sample_rate,\n",
    "        challenge=args.challenge\n",
    "    )\n",
    "    dev_data = SliceData(\n",
    "        root=args.data_path / f'{args.challenge}_val',\n",
    "        transform=DataTransform(dev_mask, args.resolution, args.challenge, use_seed=True),\n",
    "        sample_rate=args.sample_rate,\n",
    "        challenge=args.challenge,\n",
    "    )\n",
    "    return dev_data, train_data\n",
    "\n",
    "\n",
    "def create_data_loaders(args):\n",
    "    dev_data, train_data = create_datasets(args)\n",
    "    display_data = [dev_data[i] for i in range(0, len(dev_data), len(dev_data) // 16)]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    dev_loader = DataLoader(\n",
    "        dataset=dev_data,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    display_loader = DataLoader(\n",
    "        dataset=display_data,\n",
    "        batch_size=16,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, dev_loader, display_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastMriToPix2PixTransform(DataTransform):\n",
    "    def __init__(self, mask_func, resolution, which_challenge, use_seed=True):\n",
    "        super().__init__(mask_func, resolution, which_challenge, use_seed)\n",
    "    def __call__(self, kspace, target, attrs, fname, slice_):    \n",
    "        image, target, mean, std, norm = super().__call__(\n",
    "            kspace, target, attrs, fname, slice_\n",
    "        )\n",
    "        pad = nn.ConstantPad2d(padding=1, value=0)\n",
    "        return {\n",
    "            \"A\": pad(image),\n",
    "            \"B\": pad(image),\n",
    "            \"A_paths\": \"DEBUG! Do not use\",\n",
    "            \"B_paths\": \"DEBUG! Do not use\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastMriArgs = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = fastMriArgs.parse_args(\n",
    "    [\n",
    "        \"--challenge\", \"singlecoil\",\n",
    "        \"--data-path\", \"./data/\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = MaskFunc(\n",
    "    args.center_fractions,\n",
    "    args.accelerations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SliceData(\n",
    "    root=args.data_path / f'{args.challenge}_val',\n",
    "    transform=FastMriToPix2PixTransform(\n",
    "        train_mask, args.resolution, args.challenge, use_seed=True\n",
    "    ),\n",
    "    sample_rate=args.sample_rate,\n",
    "    challenge=args.challenge,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_options = TrainOptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# !python train.py --dataroot ./datasets/facades --name facades_pix2pix_mason --model pix2pix --direction BtoA\n",
    "\n",
    "!python train.py --dataroot ./datasets/facades --name facades_label2photo --model pix2pix --batch_size 16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = [\n",
    "    \"--dataroot\", \"./\",\n",
    "    \"--name\", \"train\",\n",
    "    \"--model\", \"pix2pix\",\n",
    "    \"--input_nc\", \"1\",\n",
    "    \"--output_nc\", \"1\",\n",
    "    \"--no_flip\",\n",
    "    \"--display_id\", \"-1\",\n",
    "    \"--isTrain\", \"True\",\n",
    "    \"--gpu_ids\", \"0\",\n",
    "    \"--batch_size\", \"32\",\n",
    "    \"--verbose\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_args = [\n",
    "    \"--dataroot\", \"./\",\n",
    "    \"--name\", \"train\",\n",
    "    \"--model\", \"pix2pix\",\n",
    "    \"--input_nc\", \"1\",\n",
    "    \"--output_nc\", \"1\",\n",
    "    \"--no_flip\",\n",
    "    \"--display_id\", \"-1\",\n",
    "    \"--isTrain\", \"False\",\n",
    "    \"--gpu_ids\", \"0\",\n",
    "    \"--batch_size\", \"64\",\n",
    "    \"--verbose\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_options = TrainOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = train_options.initialize(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--isTrain'], dest='isTrain', nargs=None, const=None, default=True, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options.add_argument(\"--isTrain\", default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = options.parse_args(train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pix2pix_models.pix2pix_model import Pix2PixModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "model = Pix2PixModel(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=options.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    batch1 = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch1['A'].shape())\n",
    "fakeB = model.netG(batch1['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
